{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from rdkit import Chem\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the 102 directors and extract the data \n",
    "\n",
    "\n",
    "path = \"../DUDE/DUDE\"\n",
    "#get all folders\n",
    "all_targ = os.listdir(path)\n",
    "#output = mp.Queue()\n",
    "\n",
    "#for 102 example..... get *sdf.gz\n",
    "\n",
    "\n",
    "def make_dframe(name,rad=2,bi=2048):\n",
    "    tmp_act = gzip.open(path+\"/\"+name+\"/\"+'actives_final.sdf.gz')\n",
    "    tmp_dec = gzip.open(path+\"/\"+name+\"/\"+'decoys_final.sdf.gz')\n",
    "\n",
    "        #read files\n",
    "    cont_act = Chem.ForwardSDMolSupplier(tmp_act)\n",
    "    cont_dec = Chem.ForwardSDMolSupplier(tmp_dec)\n",
    "\n",
    "        #and make a list\n",
    "    list_act = [x for x in cont_act if x is not None]\n",
    "    list_dec = [x for x in cont_dec if x is not None]\n",
    "    \n",
    "    list_act = list_act[0:10]\n",
    "    list_dec = list_dec[0:10]\n",
    "    \n",
    "    num_act = len(list_act)\n",
    "    num_dec = len(list_dec)\n",
    "\n",
    "    from rdkit.Chem import AllChem\n",
    "    npMat = np.zeros((num_act+num_dec,bi+1))\n",
    "    \n",
    "    #add active/nonactive and name as num\n",
    "   # npMat_y = np.zeros((num_act+num_dec,1))\n",
    "\n",
    "    i = 0\n",
    "    for m in list_act:\n",
    "        npMat[i,0:-1] = [x for x in AllChem.GetMorganFingerprintAsBitVect(m,rad,nBits=bi)]\n",
    "        npMat[i,-1] = 1\n",
    "      #  npMat_y[i] = 1 \n",
    "        i +=1\n",
    "    for m in list_dec:\n",
    "        npMat[i,0:-1] = [x for x in AllChem.GetMorganFingerprintAsBitVect(m,rad,nBits=bi)]\n",
    "        npMat[i,-1] = 0\n",
    "       # npMat_y[i] = 0\n",
    "        i += 1\n",
    "    return npMat#,npMat_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "first we want to load the data:\n",
    "\n",
    "- ~/Documents/git/DUDE/DUDE contains a folder for each of the 102 targets in DUDE\n",
    "- each folder contains *.ism / *.mol2 / *.sdf files for active and decoy molecules \n",
    "- to try to predict \"bioactivity\" (althouhg, how do we know that decoys are actually not active on other targers? <span style=\"color:red\">check how exactly decoys are genereated</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.740212202072144\n"
     ]
    }
   ],
   "source": [
    "pool = mp.Pool(2)\n",
    "\n",
    "import time\n",
    "\n",
    "start_t = time.time()\n",
    "result = pool.map(make_dframe, [x for x in all_targ[0:2]]) \n",
    "end_t = time.time()\n",
    "print(end_t-start_t)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get total dimention\n",
    "totalDim = 0\n",
    "for m in result:\n",
    "    totalDim += m.shape[0]\n",
    "    \n",
    "#initiate and fill main matrix\n",
    "npMat = np.zeros((totalDim,2048+1))\n",
    "i = 0\n",
    "for m in result:\n",
    "        npMat[i:i+m.shape[0],:] = m\n",
    "        i = m.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = {}\n",
    "i = 0\n",
    "for col in npMat.T:\n",
    "    feat[str(i)] = col\n",
    "    i += 1\n",
    "labels = npMat[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(1000).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_columns = []\n",
    "for key in feat.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpdmzmi7x2\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpdmzmi7x2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fba84a68fd0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers and 10 nodes in each hidden layer.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[10, 10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpdmzmi7x2/model.ckpt.\n",
      "INFO:tensorflow:loss = 70.02135, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmpdmzmi7x2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.05087628.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7fba84a68ac8>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(feat,labels,100),\n",
    "    steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
